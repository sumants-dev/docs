---
title: Application Specification
description: Core components of running the application are defined in the following specification.
---

# Specification
## Provider

* `type`- openai is only supported but we intend to support others
* `default_model`- any of supported models by the provider such as `gpt-3.5-turbo`
* `api_key` - you api key for provider

## Audit
* `type` currently only supports `basic_audit` which is a simple audit that logs the request and response to a file

## Cache
* `type` has only small_cache supported. This cache only supports small prompts for semantic caching

### Vector Collection
* `vector_collection` is the document store that stores the cache and also is anonymized by our privacy layer.
    * `type` currently supports `pgvector`
    * `conn_str` the database connection string
    * `collection_name` defines the table name to put the prompt cache in

### Embedder
* `embedder` is a the transformer applied to embed the prompt into vector collection. 
    * `type` only supports `sentence_transformer` from hugging face
    * `model` any from hugging face will work

# Example
```yaml copy
llm:
  provider:
    type: openai
    default_model: gpt-3.5-turbo
    api_key: <put-your-api-key-here>
  cache:
    type: small_cache
    vector_collection:
      type: pgvector
      conn_str: <put-your-api-key-here>
      collection_name: prompt_cache
    embedder:
      type: sentence_transformer
      model: all-MiniLM-L6-v2
```